### SETTINGS
# Copy this file and rename it to ".env" to use it.

# If ALL_LOCAL is False, we'll use OpenAI's services
# else we use whisper.cpp and piper local models
ALL_LOCAL=False
WHISPER_MODEL_NAME="ggml-tiny.en.bin"

# Uncomment and set the OpenAI API key for OpenInterpreter to work
# OPENAI_API_KEY=sk-...

# For TTS, we use the en_US-lessac-medium voice model by default
# Please change the voice URL and voice name if you wish to use another voice
PIPER_VOICE_URL="https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US/lessac/medium/"
PIPER_VOICE_NAME="en_US-lessac-medium.onnx"

# Expose through Ngrok
# Uncomment following line with your Ngrok auth token (https://dashboard.ngrok.com/get-started/your-authtoken)
#NGROK_AUTHTOKEN="AUTH TOKEN"

# If SERVER_START, this is where we'll serve the server.
# If DEVICE_START, this is where the device expects the server to be.
SERVER_URL=ws://localhost:8000/
# If you are setting up Ngrok then either change the below to Ngrok URL if running device separately, else comment it
SERVER_CONNECTION_URL=ws://localhost:8000/
SERVER_START=True
DEVICE_START=True

# Control where various operations happenâ€” can be `device` or `server`.
CODE_RUNNER=server
TTS_RUNNER=server # If device, audio will be sent over websocket.
STT_RUNNER=device # If server, audio will be sent over websocket.

# Will expose the server publically and display that URL.
SERVER_EXPOSE_PUBLICALLY=False

# Debug level
# LOG_LEVEL=DEBUG
LOG_LEVEL="INFO"